{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Overview","text":"<p>Splito is a python library designed for aiding in drug discovery by providing powerful methods for parsing and splitting datasets. It enables researchers and chemists to efficiently process data for their ML projects.</p> <p>Splito is part of the Datamol ecosystem: https://datamol.io.</p>"},{"location":"index.html#installation","title":"Installation","text":"<p>You can install <code>splito</code> using pip:</p> <pre><code>pip install splito\n</code></pre> <p>You can use conda/mamba. Ask @maclandrol for credentials to the conda forge or for a token</p> <pre><code>mamba install -c conda-forge splito\n</code></pre>"},{"location":"index.html#quick-api-tour","title":"Quick API Tour","text":"<pre><code>import datamol as dm\nfrom splito import ScaffoldSplit\n\n\n# Load some data\ndata = dm.data.chembl_drugs()\n\n# Initialize a splitter\nsplitter = ScaffoldSplit(smiles=data[\"smiles\"].tolist(), n_jobs=-1, test_size=0.2, random_state=111)\n\n# Generate indices for training set and test set\ntrain_idx, test_idx = next(splitter.split(X=data.smiles.values))\n</code></pre>"},{"location":"index.html#tutorials","title":"Tutorials","text":"<p>Check out the tutorials to get started.</p>"},{"location":"api/plot.html","title":"<code>splito.plot</code>","text":""},{"location":"api/plot.html#splito.plot","title":"splito.plot","text":""},{"location":"api/plot.html#splito.plot.plot_distance_distributions","title":"plot_distance_distributions","text":"<pre><code>plot_distance_distributions(\n    distances,\n    labels: Optional[List[str]] = None,\n    colors: Optional[List[str]] = None,\n    styles: Optional[List[str]] = None,\n    ax: Optional[plt.Axes] = None,\n    outlier_factor: Optional[float] = 3.0,\n)\n</code></pre> <p>Visualizes the distribution of distances between the clusters in the style of the MOOD paper.</p>"},{"location":"api/simpd.html","title":"<code>splito.simpd</code>","text":""},{"location":"api/simpd.html#splito.simpd.SIMPDSplitter","title":"splito.simpd.SIMPDSplitter","text":"<p>             Bases: <code>BaseShuffleSplit</code></p> <p>The SIMPD (SImulated Medicinal chemistry Project Data) is based on a multi-objective genetic algorithm (MOGA) to split a set of compounds with bioactivity data into one or more training and test sets that differ from each other in ways resembling the differences between the temporal training/test splits observed in medicinal chemistry projects.</p> <p>It's the implementation proposed in \"SIMPD: an Algorithm for Generating Simulated Time Splits for Validating Machine Learning Approaches\" available at https://chemrxiv.org/engage/chemrxiv/article-details/6406049e6642bf8c8f10e189.</p> <p>The source code has been largely inspired by the original authors implementation available at https://github.com/rinikerlab/molecular_time_series/tree/55eb420ab0319fbb18cc00fe62a872ac568ad7f5.</p>"},{"location":"api/simpd.html#splito.simpd.SIMPDSplitter.fit","title":"fit","text":"<pre><code>fit(X: np.ndarray, y: np.ndarray, groups: Optional[np.ndarray] = None)\n</code></pre> <p>Fit the splitter against a given dataset.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>An array of molecules.</p> required <code>y</code> <code>ndarray</code> <p>An array of activities (only 1D is supported).</p> required <code>groups</code> <code>Optional[ndarray]</code> <p>An array of groups.</p> <code>None</code>"},{"location":"api/simpd.html#splito.simpd.run_SIMPD","title":"splito.simpd.run_SIMPD","text":"<pre><code>run_SIMPD(\n    data: pd.DataFrame,\n    mol_column: str = \"mol\",\n    activity_column: str = \"active\",\n    pop_size: int = 500,\n    ngens: int = 100,\n    swap_fraction: float = 0.1,\n    simpd_descriptors: Optional[pd.DataFrame] = None,\n    target_train_frac_active: float = -1,\n    target_test_frac_active: float = -1,\n    target_test_set_frac: float = 0.2,\n    target_delta_test_frac_active: Optional[float] = None,\n    target_GF_delta_window: Tuple[int, int] = (10, 30),\n    target_G_val: int = 70,\n    max_population_cluster_entropy: float = 0.9,\n    pareto_weight_GF_delta: float = 10,\n    pareto_weight_G: float = 5,\n    num_threads: int = 1,\n    random_seed: Optional[int] = 19,\n    verbose: bool = True,\n    verbose_pymoo: bool = True,\n    progress: bool = True,\n    progress_leave: bool = False,\n)\n</code></pre>"},{"location":"api/simpd.html#splito.simpd.DEFAULT_SIMPD_DESCRIPTORS","title":"splito.simpd.DEFAULT_SIMPD_DESCRIPTORS  <code>module-attribute</code>","text":"<pre><code>DEFAULT_SIMPD_DESCRIPTORS = DataFrame(\n    [\n        {\n            \"name\": \"SA_Score\",\n            \"function\": \"datamol.descriptors.sas\",\n            \"target_delta_value\": 0.1 * 2.8,\n        },\n        {\n            \"name\": \"HeavyAtomCount\",\n            \"function\": \"datamol.descriptors.n_heavy_atoms\",\n            \"target_delta_value\": 0.1 * 31,\n        },\n        {\n            \"name\": \"TPSA\",\n            \"function\": \"datamol.descriptors.tpsa\",\n            \"target_delta_value\": 0.15 * 88.0,\n        },\n        {\n            \"name\": \"fr_benzene/1000 HeavyAtoms\",\n            \"function\": \"splito.simpd.descriptors.fr_benzene_1000_heavy_atoms_count\",\n            \"target_delta_value\": -0.2 * 0.44,\n        },\n    ]\n)\n</code></pre>"},{"location":"api/splito.html","title":"<code>splito</code>","text":""},{"location":"api/splito.html#basic-usage","title":"Basic usage","text":""},{"location":"api/splito.html#splito","title":"splito","text":""},{"location":"api/splito.html#splito.train_test_split","title":"train_test_split","text":"<pre><code>train_test_split(\n    X: np.ndarray,\n    y: np.ndarray,\n    molecules: Optional[Sequence[Union[str, dm.Mol]]] = None,\n    method: Union[str, SimpleSplittingMethod] = \"random\",\n    test_size: float = 0.2,\n    seed: int = None,\n    n_jobs: Optional[int] = None,\n) -&gt; tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]\n</code></pre> <p>Splits a set of molecules into a train and test set.</p> <p>Inspired by sklearn.model_selection.train_test_split, this function is meant as a convenience function that provides a less verbose way of using the different splitters.</p> <p>Examples:</p> <p>Let's first create a toy dataset</p> <pre><code>import datamol as dm\nimport numpy as np\n\ndata = dm.data.freesolv()\nsmiles = data[\"smiles\"].values\nX = np.array([dm.to_fp(dm.to_mol(smi)) for smi in smiles])\ny = data[\"expt\"].values\n</code></pre> <p>Now we can split our data.</p> <pre><code>X_train, X_test, y_train, y_test = train_test_split(X, y, method=\"random\")\n</code></pre> <p>More parameters  <pre><code>X_train, X_test, y_train, y_test = train_test_split(X, y, method=\"random\", test_size=0.1, random_state=42)\n</code></pre></p> <p>Scaffold split (note that you need to specify <code>smiles</code>):  <pre><code>X_train, X_test, y_train, y_test = train_test_split(X, y, smiles=smiles, method=\"scaffold\")\n</code></pre></p> <p>Distance-based split:  <pre><code>X_train, X_test, y_train, y_test = train_test_split(X, y, method=\"kmeans\")\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>The feature matrix.</p> required <code>y</code> <code>ndarray</code> <p>The target values.</p> required <code>molecules</code> <code>Optional[Sequence[Union[str, Mol]]]</code> <p>A list of molecules to be used for the split. Required for some splitting methods.</p> <code>None</code> <code>method</code> <code>Union[str, SimpleSplittingMethod]</code> <p>The splitting method to use. Defaults to \"random\".</p> <code>'random'</code> <code>test_size</code> <code>float</code> <p>The proportion of the dataset to include in the test split.</p> <code>0.2</code> <code>seed</code> <code>int</code> <p>The seed to use for the random number generator.</p> <code>None</code> <code>n_jobs</code> <code>Optional[int]</code> <p>The number of jobs to run in parallel.</p> <code>None</code>"},{"location":"api/splito.html#splito.train_test_split_indices","title":"train_test_split_indices","text":"<pre><code>train_test_split_indices(\n    X: np.ndarray,\n    y: np.ndarray,\n    molecules: Optional[Sequence[Union[str, dm.Mol]]] = None,\n    method: Union[str, SimpleSplittingMethod] = \"random\",\n    test_size: float = 0.2,\n    seed: int = None,\n    n_jobs: Optional[int] = None,\n) -&gt; tuple[np.ndarray, np.ndarray]\n</code></pre> <p>Returns the indices of the train and test sets.</p> <p>Different from scikit-learn's API, we assume some data-types are not represented as numpy arrays and cannot be directly indexed as we do in <code>train_test_split</code>. This functions offers a way to just return the indices and take care of the split manually.</p> <p>See <code>train_test_split</code> for more information.</p>"},{"location":"api/splito.html#advanced-usage","title":"Advanced usage","text":""},{"location":"api/splito.html#splito","title":"splito","text":""},{"location":"api/splito.html#splito.StratifiedDistributionSplit","title":"StratifiedDistributionSplit","text":"<p>             Bases: <code>GroupShuffleSplit</code></p> <p>Split a dataset using the values of a readout, so both train, test and valid have the same distribution of values. Instead of bining using some kind of interval (rolling_windows), we will instead use a 1D clustering of the readout.</p>"},{"location":"api/splito.html#splito.KMeansSplit","title":"KMeansSplit","text":"<p>             Bases: <code>GroupShuffleSplit</code></p> <p>Group-based split that uses the k-Mean clustering in the input space for splitting.</p>"},{"location":"api/splito.html#splito.MaxDissimilaritySplit","title":"MaxDissimilaritySplit","text":"<p>             Bases: <code>KMeansReducedDistanceSplitBase</code></p> <p>Splits the data such that the train and test set are maximally dissimilar.</p>"},{"location":"api/splito.html#splito.MaxDissimilaritySplit.get_split_from_distance_matrix","title":"get_split_from_distance_matrix","text":"<pre><code>get_split_from_distance_matrix(\n    mat: np.ndarray, group_indices: np.ndarray, n_train: int, n_test: int\n)\n</code></pre> <p>The Maximum Dissimilarity Split splits the data by trying to maximize the distance between train and test.</p> This is done as follows <p>(1) As initial test sample, take the data point that on average is furthest from all other samples. (2) As initial train sample, take the data point that is furthest from the initial test sample. (3) Iteratively add the train sample that is closest to the initial train sample.</p>"},{"location":"api/splito.html#splito.MolecularMinMaxSplit","title":"MolecularMinMaxSplit","text":"<p>             Bases: <code>BaseShuffleSplit</code></p> <p>Uses the Min-Max Diversity picker from RDKit and Datamol to have a diverse set of molecules in the train set.</p>"},{"location":"api/splito.html#splito.MolecularWeightSplit","title":"MolecularWeightSplit","text":"<p>             Bases: <code>BaseShuffleSplit</code></p> <p>Splits the dataset by sorting the molecules by their molecular weight and then finding an appropriate cutoff to split the molecules in two sets.</p>"},{"location":"api/splito.html#splito.MOODSplitter","title":"MOODSplitter","text":"<p>             Bases: <code>BaseShuffleSplit</code></p> <p>The MOOD splitter takes in multiple candidate splitters and a set of deployment datapoints you plan to use a model on and prescribes one splitting method that creates the test set that is most representative of the deployment set.</p>"},{"location":"api/splito.html#splito.MOODSplitter.prescribed_splitter_label","title":"prescribed_splitter_label  <code>property</code>","text":"<pre><code>prescribed_splitter_label\n</code></pre> <p>Textual identifier of the splitting method that was deemed most representative.</p>"},{"location":"api/splito.html#splito.MOODSplitter.visualize","title":"visualize","text":"<pre><code>visualize(\n    downstream_distances: np.ndarray,\n    splits: Optional[List[_SplitCharacterization]] = None,\n    ax: Optional[plt.Axes] = None,\n)\n</code></pre> <p>Visualizes the results of the splitting protocol by visualizing the test-to-train distance distributions resulting from each of the candidate splitters and coloring them based on their representativeness.</p>"},{"location":"api/splito.html#splito.MOODSplitter.score_representativeness","title":"score_representativeness  <code>staticmethod</code>","text":"<pre><code>score_representativeness(\n    downstream_distances, distances, num_samples: int = 100\n)\n</code></pre> <p>Scores a candidate split by comparing the test-to-train and deployment-to-dataset distributions. A higher score should be interpreted as more representative</p>"},{"location":"api/splito.html#splito.MOODSplitter.get_prescribed_splitter","title":"get_prescribed_splitter","text":"<pre><code>get_prescribed_splitter() -&gt; BaseShuffleSplit\n</code></pre> <p>Returns the prescribed scikit-learn Splitter object that is most representative</p>"},{"location":"api/splito.html#splito.MOODSplitter.get_protocol_visualization","title":"get_protocol_visualization","text":"<pre><code>get_protocol_visualization() -&gt; plt.Axes\n</code></pre> <p>Visualizes the results of the splitting protocol</p>"},{"location":"api/splito.html#splito.MOODSplitter.get_protocol_results","title":"get_protocol_results","text":"<pre><code>get_protocol_results() -&gt; pd.DataFrame\n</code></pre> <p>Returns the results of the splitting protocol in tabular form</p>"},{"location":"api/splito.html#splito.MOODSplitter.fit","title":"fit","text":"<pre><code>fit(\n    X: np.ndarray,\n    y: Optional[np.ndarray] = None,\n    groups: Optional[np.ndarray] = None,\n    X_deployment: Optional[np.ndarray] = None,\n    deployment_distances: Optional[np.ndarray] = None,\n    progress: bool = False,\n)\n</code></pre> <p>Follows the MOOD specification protocol to prescribe a train-test split that is most representative of the deployment setting and as such closes the testing-deployment gap.</p> <p>The k-NN distance in the representation space is used as a proxy of difficulty. The further a datapoint is from the training set, the lower the expected model's performance. Using that observation, we select the train-test split that best replicates the distance distribution (i.e. \"the difficulty\") of the deployment set.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>An array of (n_samples, n_features)</p> required <code>y</code> <code>Optional[ndarray]</code> <p>An array of (n_samples, 1) targets, passed to candidate splitter's split() method</p> <code>None</code> <code>groups</code> <code>Optional[ndarray]</code> <p>An array of (n_samples,) groups, passed to candidate splitter's split() method</p> <code>None</code> <code>X_deployment</code> <code>Optional[ndarray]</code> <p>An array of (n_deployment_samples, n_features)</p> <code>None</code> <code>deployment_distances</code> <code>Optional[ndarray]</code> <p>An array of (n_deployment_samples, 1) precomputed distances.</p> <code>None</code> <code>progress</code> <code>bool</code> <p>Whether to show a progress bar</p> <code>False</code>"},{"location":"api/splito.html#splito.PerimeterSplit","title":"PerimeterSplit","text":"<p>             Bases: <code>KMeansReducedDistanceSplitBase</code></p> <p>Places the pairs of data points with maximal pairwise distance in the test set. This was originally called the extrapolation-oriented split, introduced in  Sz\u00e1ntai-Kis et. al., 2003</p>"},{"location":"api/splito.html#splito.PerimeterSplit.get_split_from_distance_matrix","title":"get_split_from_distance_matrix","text":"<pre><code>get_split_from_distance_matrix(\n    mat: np.ndarray, group_indices: np.ndarray, n_train: int, n_test: int\n)\n</code></pre> <p>Iteratively places the pairs of data points with maximal pairwise distance in the test set. Anything that remains is added to the train set.</p> <p>Intuitively, this leads to a test set where all the datapoints are on the \"perimeter\" of the high-dimensional data cloud.</p>"},{"location":"api/splito.html#splito.ScaffoldSplit","title":"ScaffoldSplit","text":"<p>             Bases: <code>GroupShuffleSplit</code></p> <p>The default scaffold split popular in molecular modeling literature</p>"},{"location":"api/utils.html","title":"<code>splito.utils</code>","text":""},{"location":"api/utils.html#splito.utils","title":"splito.utils","text":""},{"location":"api/utils.html#splito.utils.EmpiricalKernelMapTransformer","title":"EmpiricalKernelMapTransformer","text":"<p>Transforms a dataset using the Empirical Kernel Map method. In this, a point is defined by its distance to a set of reference points. After this transformation, one can use the euclidean metric even if the original space was not euclidean compatible.</p>"},{"location":"api/utils.html#splito.utils.EmpiricalKernelMapTransformer.__call__","title":"__call__","text":"<pre><code>__call__(X)\n</code></pre> <p>Transforms a list of datapoints</p>"},{"location":"api/utils.html#splito.utils.EmpiricalKernelMapTransformer.transform","title":"transform","text":"<pre><code>transform(X)\n</code></pre> <p>Transforms a single datapoint</p>"},{"location":"api/utils.html#splito.utils.get_iqr_outlier_bounds","title":"get_iqr_outlier_bounds","text":"<pre><code>get_iqr_outlier_bounds(X, factor: float = 1.5)\n</code></pre> <p>Return the bounds for outliers using the Inter-Quartile Range (IQR) method. Returns a lower and upper bound. Any value exceeding these bounds is considered an outlier.</p>"},{"location":"api/utils.html#splito.utils.get_kmeans_clusters","title":"get_kmeans_clusters","text":"<pre><code>get_kmeans_clusters(\n    X,\n    n_clusters: int,\n    random_state: Optional[int] = None,\n    return_centers: bool = False,\n    base_metric: str = \"euclidean\",\n)\n</code></pre> <p>Get the k-means clusters for a set of datapoints</p> <p>If the base metric is not euclidean, we use the Empirical Kernel Map to transform the data into a euclidean compatible space.</p>"},{"location":"tutorials/MOOD_Protocol.html","title":"MOOD Protocol","text":"<p>As model selection is often argued to improve generalization, we investigate what molecular splitting strategy mimics the deployment distribution the best. The investigation measures the representativeness of various candidate splitting methods.</p> <ol> <li>Compute the distance of each molecule in the deployment set(s) to the training set. This step gives the \u201cdeployment-to-train\u201d distribution which is the target distance distribution that should be mimicked during model selection to better generalize during deployment. If the final model will be retrained on the full-dataset before deployment, the distances must be computed w.r.t the full dataset instead of just the training partition.</li> <li>Characterize each splitting method by splitting the dataset into a train and test sets. Then, compute the distance of each test sample to the training set to get the \u201ctest-to-train\u201d distribution. For small datasets, this step should be repeated with multiple seeds to get more reliable estimates of the test-to-train distribution before doing the final split that will be used for training.</li> <li>Score the different splitting methods by measuring the distance between their test-to-train distribution and the deployment-to-train distance distribution. Then, select the splitting method that has the lowest distance for model selection. Here, we use the Jenssen-Shannon distance between the distributions.</li> </ol> <p>This protocol is implemented in the MOODSplitter. See an example of how to use the it below:</p> In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport numpy as np\nimport datamol as dm\n\nfrom sklearn.model_selection import ShuffleSplit\n\nimport splito\n</pre> %load_ext autoreload %autoreload 2  import numpy as np import datamol as dm  from sklearn.model_selection import ShuffleSplit  import splito In\u00a0[3]: Copied! <pre># Load the training dataset\ndataset = dm.data.solubility()\ndataset_feat = [dm.to_fp(mol) for mol in dataset.mol]\n\n# Load the deployment set\n# Alternatively, you can also load an array of deployment-to-dataset distance\ndeployment_feat = [dm.to_fp(mol) for mol in dm.data.chembl_drugs()[\"smiles\"]]\n</pre> # Load the training dataset dataset = dm.data.solubility() dataset_feat = [dm.to_fp(mol) for mol in dataset.mol]  # Load the deployment set # Alternatively, you can also load an array of deployment-to-dataset distance deployment_feat = [dm.to_fp(mol) for mol in dm.data.chembl_drugs()[\"smiles\"]] In\u00a0[4]: Copied! <pre># Define the candidate splitters\n# Since we use the scikit-learn interface, this can also be sklearn Splitters\nsplitters = {\n    \"Random\": ShuffleSplit(),\n    \"Scaffold\": splito.ScaffoldSplit(dataset.mol.values),\n    \"Perimeter\": splito.PerimeterSplit(),\n    \"MaxDissimilarity\": splito.MaxDissimilaritySplit(),\n}\n\nsplitter = splito.MOODSplitter(splitters)\n</pre> # Define the candidate splitters # Since we use the scikit-learn interface, this can also be sklearn Splitters splitters = {     \"Random\": ShuffleSplit(),     \"Scaffold\": splito.ScaffoldSplit(dataset.mol.values),     \"Perimeter\": splito.PerimeterSplit(),     \"MaxDissimilarity\": splito.MaxDissimilaritySplit(), }  splitter = splito.MOODSplitter(splitters) In\u00a0[5]: Copied! <pre># get the rank of the splitting methods with the givent deployment set\nsplitter.fit(X=np.stack(dataset_feat), X_deployment=np.stack(deployment_feat))\n</pre> # get the rank of the splitting methods with the givent deployment set splitter.fit(X=np.stack(dataset_feat), X_deployment=np.stack(deployment_feat)) <pre>2023-09-22 08:57:15.795 | INFO     | splito._mood_split:fit:308 - Ranked all different splitting methods:\n              split  representativeness   best  rank\n0            Random            0.375938  False   4.0\n1          Scaffold            0.492793  False   3.0\n2         Perimeter            0.526232  False   2.0\n3  MaxDissimilarity            0.552740   True   1.0\n2023-09-22 08:57:15.795 | INFO     | splito._mood_split:fit:309 - Selected MaxDissimilarity as the most representative splitting method\n</pre> Out[5]: split representativeness best rank 0 Random 0.375938 False 4.0 1 Scaffold 0.492793 False 3.0 2 Perimeter 0.526232 False 2.0 3 MaxDissimilarity 0.552740 True 1.0 <p>With the given deployment, the best splitting method to ensure the generalization is the <code>PerimeterSplit</code>.</p> <ul> <li>The End :-)</li> </ul>"},{"location":"tutorials/MPO_Splitters.html","title":"MPO Splitters","text":"<ul> <li>Approach:  This approach utilizes multi-objective genetic algorithms to split data into training and test sets. The test set consists of data that exhibits a better profile of the predefined objectives commonly used in drug discovery project.</li> <li>Characteristics: The goal of using multi-objective optimization algorithms to split datasets is to mimic the differences in molecular properties observed in real-world medicinal chemistry project datasets. This method provides a reliable estimate of the model's ability to generalize to new data. It can also be valuable for answering relevant questions in drug discovery, such as \"Is it possible to make predictions on compounds with a better profile than the compounds on which the model was trained?\"</li> <li>Application: Most of the drug development projects requires a number of iterations of molecular design and experimental validation over a series of time points. The subsequent design cycles typically involve molecules that have one or multiple improved features in their molecular profile. These improvements may include a wider range of molecular weight, new chemical structures and scaffolds that are important for structure-activity relationship (SAR), enhanced bioactivity, improved drug metabolism and pharmacokinetic properties, and more. In these cases, this approach provides a robust estimate of the model's ability to generalize to new data. A model chosen through this splitting approach proves highly valuable in the lead optimization phase. However, if the molecular profiles have no significant changes in the dataset, applying the this split would have no difference to a random split.</li> <li>Code availability: <code>splito.simpd.SIMPDSplitter</code></li> </ul> In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport datamol as dm\n\nfrom splito.simpd import SIMPDSplitter\n\nfrom utils import visualize_chemspace\n</pre> %load_ext autoreload %autoreload 2  import datamol as dm  from splito.simpd import SIMPDSplitter  from utils import visualize_chemspace In\u00a0[2]: Copied! <pre># load dataset\ndata = dm.data.solubility()\ndata.head(5)\n</pre> # load dataset data = dm.data.solubility() data.head(5) Out[2]: mol ID NAME SOL SOL_classification smiles split 0 &lt;rdkit.Chem.rdchem.Mol object at 0x7f8bfb7a9540&gt; 1 n-pentane -3.18 (A) low CCCCC train 1 &lt;rdkit.Chem.rdchem.Mol object at 0x7f8bfb7a95b0&gt; 2 cyclopentane -2.64 (B) medium C1CCCC1 train 2 &lt;rdkit.Chem.rdchem.Mol object at 0x7f8bfb7a9620&gt; 3 n-hexane -3.84 (A) low CCCCCC train 3 &lt;rdkit.Chem.rdchem.Mol object at 0x7f8bfb7a9690&gt; 4 2-methylpentane -3.74 (A) low CCCC(C)C train 4 &lt;rdkit.Chem.rdchem.Mol object at 0x7f8bfb7a9700&gt; 6 2,2-dimethylbutane -3.55 (A) low CCC(C)(C)C train In\u00a0[3]: Copied! <pre>data.groupby(\"SOL_classification\")[\"SOL\"].hist(bins=20)\n</pre> data.groupby(\"SOL_classification\")[\"SOL\"].hist(bins=20) Out[3]: <pre>SOL_classification\n(A) low       Axes(0.125,0.11;0.775x0.77)\n(B) medium    Axes(0.125,0.11;0.775x0.77)\n(C) high      Axes(0.125,0.11;0.775x0.77)\nName: SOL, dtype: object</pre> In\u00a0[4]: Copied! <pre>data_col = \"CLASS_SOL\"\nmol_col = \"mol\"\n</pre> data_col = \"CLASS_SOL\" mol_col = \"mol\" <p>The current version of <code>SIMPDSplitter</code> implementation only support binary data value. Therefore, we convert the <code>SOL_classification</code> to binary format by setting <code>(C) high</code> as <code>positive</code> and the rest are <code>negative</code>.</p> In\u00a0[5]: Copied! <pre>data.loc[data[\"SOL_classification\"] == \"(C) high\", data_col] = 1\ndata.loc[data[\"SOL_classification\"] != \"(C) high\", data_col] = 0\n</pre> data.loc[data[\"SOL_classification\"] == \"(C) high\", data_col] = 1 data.loc[data[\"SOL_classification\"] != \"(C) high\", data_col] = 0 In\u00a0[6]: Copied! <pre># the running time is considerable long. The parameters should also be improved.\nargs = {}\nargs[\"n_splits\"] = 5\n</pre> # the running time is considerable long. The parameters should also be improved. args = {} args[\"n_splits\"] = 5 <p>Genetic algorithm parameters</p> In\u00a0[7]: Copied! <pre>args[\"pop_size\"] = 500\nargs[\"ngens\"] = 10\n</pre> args[\"pop_size\"] = 500 args[\"ngens\"] = 10 <p>SIMPD objectives and constraints</p> <p>Eight objectives were selected for the MOGA, based the analysis of descriptor differences and the spatial statistics between training and test sets in the NIBR medicinal chemistry projects:  1.$\u2206_{test-train}median(SA\\_Score)=0.28$  2.$\u2206_{test-train}median(HeavyAtomCount)=3.1$  3.$\u2206_{test-train}median(TPSA)=13.2$  4.$\u2206_{test-train}median(fr\\_benzene/1000\\ HeavyAtoms)=-8.8$  5.$frac_{active}(train)=value\\ from\\ dataset$  6.$frac_{active}(test)=value\\ from\\ dataset$  7.$10&lt;\\sum_{G}\u2212\\sum_{F\u2032}&lt;30 $  8.$\\sum_{G}&gt;70$</p> <p>See more details in:</p> <ul> <li>https://chemrxiv.org/engage/chemrxiv/article-details/6406049e6642bf8c8f10e189</li> <li><code>splito.simpd.SIMPDSpliter</code></li> </ul> In\u00a0[8]: Copied! <pre>args[\"simpd_descriptors\"] = None\nargs[\"target_train_frac_active\"] = -1\nargs[\"target_test_frac_active\"] = -1\nargs[\"target_delta_test_frac_active\"] = None  # [0.11, 0.30] or None\nargs[\"target_GF_delta_window\"] = (10, 30)\nargs[\"target_G_val\"] = 70\nargs[\"max_population_cluster_entropy\"] = 0.9\nargs[\"pareto_weight_GF_delta\"] = 10\nargs[\"pareto_weight_G\"] = 5\n</pre> args[\"simpd_descriptors\"] = None args[\"target_train_frac_active\"] = -1 args[\"target_test_frac_active\"] = -1 args[\"target_delta_test_frac_active\"] = None  # [0.11, 0.30] or None args[\"target_GF_delta_window\"] = (10, 30) args[\"target_G_val\"] = 70 args[\"max_population_cluster_entropy\"] = 0.9 args[\"pareto_weight_GF_delta\"] = 10 args[\"pareto_weight_G\"] = 5 <p>Other parameters</p> In\u00a0[9]: Copied! <pre>args[\"num_threads\"] = 4\nargs[\"random_seed\"] = 111\nargs[\"verbose\"] = True\nargs[\"verbose_pymoo\"] = True\nargs[\"progress\"] = True\nargs[\"progress_leave\"] = True\n</pre> args[\"num_threads\"] = 4 args[\"random_seed\"] = 111 args[\"verbose\"] = True args[\"verbose_pymoo\"] = True args[\"progress\"] = True args[\"progress_leave\"] = True <p>Define the splitter and fit with the dataset</p> In\u00a0[10]: Copied! <pre>simpd_splitter = SIMPDSplitter(**args)\nresult = simpd_splitter.fit(data[mol_col].values, data[data_col].values)\n</pre> simpd_splitter = SIMPDSplitter(**args) result = simpd_splitter.fit(data[mol_col].values, data[data_col].values) <pre>2023-09-22 08:54:59.310 | INFO     | splito.simpd.preprocess:preprocess_SIMPD_mols:55 - Compute descriptors and fingerprint values for the molecules.\n</pre> <pre>Preprocess molecules:   0%|          | 0/1282 [00:00&lt;?, ?it/s]</pre> <pre>2023-09-22 08:54:59.937 | INFO     | splito.simpd.preprocess:preprocess_SIMPD_mols:78 - Compute the distance matrix for the molecules.\n2023-09-22 08:55:02.180 | INFO     | splito.simpd.simpd:run_SIMPD:92 - Working with 1282 points and picking 256\n2023-09-22 08:55:02.303 | INFO     | splito.simpd.simpd:run_SIMPD:108 - Clustering the starting points with a distance threshold of 0.65 and a cluster size threshold of 25.64.\n2023-09-22 08:55:02.303 | INFO     | splito.simpd.simpd:run_SIMPD:111 - 2 clusters have been created of size: [380, 902]\n2023-09-22 08:55:02.305 | INFO     | splito.simpd.simpd:run_SIMPD:145 - Start the optimization.\n</pre> <pre>Optimization:   0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> <pre>==========================================================================================\nn_gen  |  n_eval  | n_nds  |     cv_min    |     cv_avg    |      eps      |   indicator  \n==========================================================================================\n     1 |        2 |      2 |  0.000000E+00 |  0.000000E+00 |             - |             -\n     2 |      502 |     50 |  0.000000E+00 |  1.9557361575 |  0.2274187073 |         ideal\n     3 |     1002 |    104 |  0.000000E+00 |  0.3826700117 |  0.5349135632 |         ideal\n     4 |     1502 |    143 |  0.000000E+00 |  0.0545726551 |  0.1102588686 |         ideal\n     5 |     2002 |    168 |  0.000000E+00 |  0.0194028872 |  0.0392100744 |         nadir\n     6 |     2502 |    197 |  0.000000E+00 |  0.0058331106 |  0.0919958420 |         nadir\n     7 |     3002 |    236 |  0.000000E+00 |  0.000000E+00 |  0.0893106893 |         nadir\n     8 |     3502 |    265 |  0.000000E+00 |  0.000000E+00 |  0.0214258827 |         ideal\n     9 |     4002 |    301 |  0.000000E+00 |  0.000000E+00 |  0.0292862684 |         nadir\n</pre> <pre>2023-09-22 08:55:09.495 | INFO     | splito.simpd.simpd:run_SIMPD:173 - Found 330 solutions\n2023-09-22 08:55:09.495 | INFO     | splito.simpd.simpd:run_SIMPD:176 - Scoring the solutions.\n2023-09-22 08:55:09.496 | INFO     | splito.simpd.simpd:run_SIMPD:195 - Objective values for the best solution: [ 0.13588097  9.1        27.11       71.34057143  0.15186232  0.\n  7.31640625]\n</pre> <pre>    10 |     4502 |    330 |  0.000000E+00 |  0.000000E+00 |  0.0038477279 |         ideal\n</pre> <p>In all the generations, five of them are successful, one failed and three are inconclusive. The best solution will be used for splitting the data.</p> In\u00a0[11]: Copied! <pre>train_idx, test_idx = next(simpd_splitter.split(data[mol_col].values))\n</pre> train_idx, test_idx = next(simpd_splitter.split(data[mol_col].values)) In\u00a0[12]: Copied! <pre>data.loc[train_idx, \"SIMPDSplit\"] = \"train\"\ndata.loc[test_idx, \"SIMPDSplit\"] = \"test\"\n</pre> data.loc[train_idx, \"SIMPDSplit\"] = \"train\" data.loc[test_idx, \"SIMPDSplit\"] = \"test\" In\u00a0[13]: Copied! <pre>visualize_chemspace(data, split_names=[\"SIMPDSplit\"], mol_col=mol_col, size_col=\"CLASS_SOL\")\n</pre> visualize_chemspace(data, split_names=[\"SIMPDSplit\"], mol_col=mol_col, size_col=\"CLASS_SOL\") Out[13]: <pre>&lt;Figure size 640x480 with 0 Axes&gt;</pre> <pre>&lt;Figure size 640x480 with 0 Axes&gt;</pre> <ul> <li>The End :-)</li> </ul>"},{"location":"tutorials/MPO_Splitters.html#define-parameters-for-simpdsplitter","title":"Define parameters for <code>SIMPDSplitter</code>\u00b6","text":""},{"location":"tutorials/MPO_Splitters.html#analysis","title":"Analysis\u00b6","text":""},{"location":"tutorials/Other_Splitters.html","title":"Other Splitters","text":"<ul> <li>MolecularWeightSplit</li> <li>StratifiedDistributionSplit</li> </ul> In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport datamol as dm\nimport splito\n\nfrom utils import visualize_chemspace\n</pre> %load_ext autoreload %autoreload 2  import datamol as dm import splito  from utils import visualize_chemspace In\u00a0[9]: Copied! <pre># load dataset\ndata = dm.data.chembl_drugs()\ndata.head(5)\n</pre> # load dataset data = dm.data.chembl_drugs() data.head(5) Out[9]: smiles 0 Br.CC(N)Cc1ccc(O)cc1 1 Br.CC(NC(C)(C)C)C(=O)c1cccc(Cl)c1 2 Br.CC1C2Cc3ccc(O)cc3C1(C)CCN2CCc1ccccc1 3 Br.CCN(c1cc(-c2ccc(CN3CCOCC3)cc2)cc(C(=O)NCc2c... 4 Br.CN(C)CCCC1(c2ccc(F)cc2)OCc2cc(C#N)ccc21 In\u00a0[10]: Copied! <pre>splitter = splito.MolecularWeightSplit(test_size=0.2, random_state=111, generalize_to_larger=True)\ntrain_idx, test_idx = next(splitter.split(X=data.smiles.tolist()))\nassert train_idx.shape[0] &gt; test_idx.shape[0]\n\ndata.loc[train_idx, \"MolecularWeightSplit\"] = \"train\"\ndata.loc[test_idx, \"MolecularWeightSplit\"] = \"test\"\n</pre> splitter = splito.MolecularWeightSplit(test_size=0.2, random_state=111, generalize_to_larger=True) train_idx, test_idx = next(splitter.split(X=data.smiles.tolist())) assert train_idx.shape[0] &gt; test_idx.shape[0]  data.loc[train_idx, \"MolecularWeightSplit\"] = \"train\" data.loc[test_idx, \"MolecularWeightSplit\"] = \"test\" <pre>2023-09-22 08:59:53.879 | WARNING  | splito._molecular_weight:_iter_indices:66 - n_splits=5 &gt; 1, but MolecularWeightSplit is deterministic and will always return the same split!\n</pre> In\u00a0[11]: Copied! <pre>data[\"mw\"] = data.smiles.apply(lambda smi: dm.descriptors.mw(dm.to_mol(smi)))\n</pre> data[\"mw\"] = data.smiles.apply(lambda smi: dm.descriptors.mw(dm.to_mol(smi))) In\u00a0[12]: Copied! <pre>data.groupby(by=\"MolecularWeightSplit\")[\"mw\"].hist(legend=True)\n</pre> data.groupby(by=\"MolecularWeightSplit\")[\"mw\"].hist(legend=True) Out[12]: <pre>MolecularWeightSplit\ntest     Axes(0.125,0.11;0.775x0.77)\ntrain    Axes(0.125,0.11;0.775x0.77)\nName: mw, dtype: object</pre> In\u00a0[13]: Copied! <pre>visualize_chemspace(data, split_names=[\"MolecularWeightSplit\"])\n</pre> visualize_chemspace(data, split_names=[\"MolecularWeightSplit\"]) Out[13]: <pre>&lt;Figure size 640x480 with 0 Axes&gt;</pre> <pre>&lt;Figure size 640x480 with 0 Axes&gt;</pre> In\u00a0[14]: Copied! <pre># load dataset\ndata = dm.data.freesolv()\ndata.head(5)\n</pre> # load dataset data = dm.data.freesolv() data.head(5) Out[14]: iupac smiles expt calc 0 4-methoxy-N,N-dimethyl-benzamide CN(C)C(=O)c1ccc(cc1)OC -11.01 -9.625 1 methanesulfonyl chloride CS(=O)(=O)Cl -4.87 -6.219 2 3-methylbut-1-ene CC(C)C=C 1.83 2.452 3 2-ethylpyrazine CCc1cnccn1 -5.45 -5.809 4 heptan-1-ol CCCCCCCO -4.21 -2.917 In\u00a0[15]: Copied! <pre>splitter = splito.StratifiedDistributionSplit(test_size=0.2, random_state=111)\ntrain_idx, test_idx = next(splitter.split(X=data[\"smiles\"].tolist(), y=data.expt.tolist()))\nassert train_idx.shape[0] &gt; test_idx.shape[0]\n\ndata.loc[train_idx, \"StratifiedDistributionSplit\"] = \"train\"\ndata.loc[test_idx, \"StratifiedDistributionSplit\"] = \"test\"\n</pre> splitter = splito.StratifiedDistributionSplit(test_size=0.2, random_state=111) train_idx, test_idx = next(splitter.split(X=data[\"smiles\"].tolist(), y=data.expt.tolist())) assert train_idx.shape[0] &gt; test_idx.shape[0]  data.loc[train_idx, \"StratifiedDistributionSplit\"] = \"train\" data.loc[test_idx, \"StratifiedDistributionSplit\"] = \"test\" <p>Check the distributions of train/test set</p> In\u00a0[16]: Copied! <pre>data.groupby(by=\"StratifiedDistributionSplit\")[\"expt\"].plot.density(legend=True)\n</pre> data.groupby(by=\"StratifiedDistributionSplit\")[\"expt\"].plot.density(legend=True) Out[16]: <pre>StratifiedDistributionSplit\ntest     Axes(0.125,0.11;0.775x0.77)\ntrain    Axes(0.125,0.11;0.775x0.77)\nName: expt, dtype: object</pre> In\u00a0[17]: Copied! <pre>visualize_chemspace(data, split_names=[\"StratifiedDistributionSplit\"])\n</pre> visualize_chemspace(data, split_names=[\"StratifiedDistributionSplit\"]) Out[17]: <pre>&lt;Figure size 640x480 with 0 Axes&gt;</pre> <pre>&lt;Figure size 640x480 with 0 Axes&gt;</pre> <ul> <li>The End :-)</li> </ul>"},{"location":"tutorials/Other_Splitters.html#molecularweightsplit","title":"MolecularWeightSplit\u00b6","text":"<p>Splits the dataset by sorting the molecules by their molecular weight and then finding an appropriate cutoff to split the molecules in two sets. The application use-case is to train a model which is able to learn the SAR from small molecules and aim to generalize the larger molecules.</p>"},{"location":"tutorials/Other_Splitters.html#stratifieddistributionsplit","title":"StratifiedDistributionSplit\u00b6","text":"<p>Split a dataset using the values of a readout, so both train, test and valid have the same distribution of values. Instead of binning using some kind of interval, we will instead use a 1D clustering of the readout.</p>"},{"location":"tutorials/Structure_based_Splitters.html","title":"Structure-based Splitters","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport datamol as dm\nimport splito\n\nfrom utils import visualize_chemspace\n</pre> %load_ext autoreload %autoreload 2  import datamol as dm import splito  from utils import visualize_chemspace In\u00a0[2]: Copied! <pre># Load dataset\ndata = dm.data.freesolv()\ndata.head(10)\n</pre> # Load dataset data = dm.data.freesolv() data.head(10) Out[2]: iupac smiles expt calc 0 4-methoxy-N,N-dimethyl-benzamide CN(C)C(=O)c1ccc(cc1)OC -11.01 -9.625 1 methanesulfonyl chloride CS(=O)(=O)Cl -4.87 -6.219 2 3-methylbut-1-ene CC(C)C=C 1.83 2.452 3 2-ethylpyrazine CCc1cnccn1 -5.45 -5.809 4 heptan-1-ol CCCCCCCO -4.21 -2.917 5 3,5-dimethylphenol Cc1cc(cc(c1)O)C -6.27 -5.444 6 2,3-dimethylbutane CC(C)C(C)C 2.34 2.468 7 2-methylpentan-2-ol CCCC(C)(C)O -3.92 -2.779 8 1,2-dimethylcyclohexane C[C@@H]1CCCC[C@@H]1C 1.58 1.685 9 butan-2-ol CC[C@H](C)O -4.62 -3.145 In\u00a0[3]: Copied! <pre># Define PerimeterSplit\nsplitter = splito.PerimeterSplit(n_jobs=-1, test_size=0.2, random_state=111)\ntrain_idx, test_idx = next(splitter.split(X=data[\"smiles\"].values))\n\nassert train_idx.shape[0] &gt; test_idx.shape[0]\n\ndata.loc[train_idx, splito.PerimeterSplit.__name__] = \"train\"\ndata.loc[test_idx, splito.PerimeterSplit.__name__] = \"test\"\n</pre> # Define PerimeterSplit splitter = splito.PerimeterSplit(n_jobs=-1, test_size=0.2, random_state=111) train_idx, test_idx = next(splitter.split(X=data[\"smiles\"].values))  assert train_idx.shape[0] &gt; test_idx.shape[0]  data.loc[train_idx, splito.PerimeterSplit.__name__] = \"train\" data.loc[test_idx, splito.PerimeterSplit.__name__] = \"test\" <pre>2023-09-22 08:47:55.053 | DEBUG    | splito.utils:get_kmeans_clusters:68 - To use KMeans with the jaccard metric, we use the Empirical Kernel Map\n</pre> In\u00a0[4]: Copied! <pre># Define PerimeterSplit\nsplitter = splito.MaxDissimilaritySplit(n_jobs=-1, test_size=0.2, random_state=111)\ntrain_idx, test_idx = next(splitter.split(X=data.smiles.values))\nassert train_idx.shape[0] &gt; test_idx.shape[0]\n\ndata.loc[train_idx, \"MaxDissimilaritySplit\"] = \"train\"\ndata.loc[test_idx, \"MaxDissimilaritySplit\"] = \"test\"\n</pre> # Define PerimeterSplit splitter = splito.MaxDissimilaritySplit(n_jobs=-1, test_size=0.2, random_state=111) train_idx, test_idx = next(splitter.split(X=data.smiles.values)) assert train_idx.shape[0] &gt; test_idx.shape[0]  data.loc[train_idx, \"MaxDissimilaritySplit\"] = \"train\" data.loc[test_idx, \"MaxDissimilaritySplit\"] = \"test\" <pre>2023-09-22 08:53:01.057 | DEBUG    | splito.utils:get_kmeans_clusters:68 - To use KMeans with the jaccard metric, we use the Empirical Kernel Map\n</pre> In\u00a0[5]: Copied! <pre>visualize_chemspace(data, split_names=[\"PerimeterSplit\", \"MaxDissimilaritySplit\"])\n</pre> visualize_chemspace(data, split_names=[\"PerimeterSplit\", \"MaxDissimilaritySplit\"]) Out[5]: <pre>&lt;Figure size 640x480 with 0 Axes&gt;</pre> <pre>&lt;Figure size 640x480 with 0 Axes&gt;</pre> <ul> <li>The End :-)</li> </ul>"},{"location":"tutorials/Structure_based_Splitters.html","title":"\u00b6","text":""},{"location":"tutorials/Structure_based_Splitters.html#goal","title":"Goal\u00b6","text":"<p>Both splitting methods are designed to increase the distance between the train and the test sets. The goal of using such splitting approach is to select models with better generalization capability.</p>"},{"location":"tutorials/Structure_based_Splitters.html#perimetersplit","title":"PerimeterSplit\u00b6","text":"<ul> <li>Places the pairs of data points with maximal pairwise distance in the test set.</li> <li>This was originally called the extrapolation-oriented split, introduced in Sz\u00e1ntai-Kis et. al., 2003</li> </ul> <p>The perimeter split aims to select molecules that are on the outskirts of the molecular distribution by iteratively selecting the two molecules that are furthest away from each other and adding them to the test set. For model selection, it was found to lead to models that extrapolate (or generalize) better.</p>"},{"location":"tutorials/Structure_based_Splitters.html#maxdissimilaritysplit","title":"MaxDissimilaritySplit\u00b6","text":"<p>The Maximum Dissimilarity Split splits the data by trying to maximize the distance between train and test. This is done as follows:</p> <ol> <li>As an initial test sample, take the data point that on average is furthest from all other samples.</li> <li>As initial train sample, take the data point that is furthest from the initial test sample.</li> <li>Iteratively add the train sample that is closest to the initial train sample.</li> </ol> <p>The maximum dissimilarity split finds a split that maximizes the dissimilarity between train and test sets. To do so, the two most dissimilar molecules are each assigned to either set. Then, molecules that are closest to the first test molecule are iteratively added to the test set until the desired size is reached.</p>"},{"location":"tutorials/Structure_based_Splitters.html#analysis","title":"Analysis\u00b6","text":"<p>Check the distributions of train/test set generated by the <code>PerimeterSplit</code> and <code>MaxDissimilaritySplit</code> in the chemical space.</p>"},{"location":"tutorials/The_Basics.html","title":"Splitting dataset with splito","text":"<p>This notebook demonstrates the basic usage of <code>splito</code> library for data splitting.</p> <p>Example:</p> <ul> <li>Scaffold-based split:<ul> <li>Approach: Performing a scaffold split involves partitioning a chemical dataset based on common structure to ensure that the training and test sets contain distinct chemical structures while maintaining the diversity of scaffolds.</li> <li>Characteristics:  In certain studies, data points may be correlated due to shared characteristics such as similar structure or same scaffold. Structure/scaffold-based splitting ensures that the model is tested on structure/scaffold it has never seen before, which is crucial for assessing its ability to generalize to new chemical structures.</li> <li>Application: The effectiveness of a scaffold split depends on the diversity of scaffolds in your dataset. It's important to ensure that the selected scaffolds are representative of the chemical space you're interested in exploring. Additionally, this approach is most useful when the scaffolds have significant impact on the bioactivity or other properties of interest. Therefore, such splitting approach is often used in lead optimization stage where there are multiple advanced series of molecules with better understanding SAR to be optimized.</li> </ul> </li> </ul> In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\n\nimport datamol as dm\nimport splito\n\nfrom utils import visualize_chemspace\n</pre> %load_ext autoreload %autoreload 2   import datamol as dm import splito  from utils import visualize_chemspace In\u00a0[2]: Copied! <pre>data = dm.data.chembl_drugs()  # might change to another dataset which fits for scaffold split\n</pre> data = dm.data.chembl_drugs()  # might change to another dataset which fits for scaffold split In\u00a0[3]: Copied! <pre># Define scaffold split\nsplitter = splito.ScaffoldSplit(smiles=data.smiles.tolist(), n_jobs=-1, test_size=0.2, random_state=111)\n</pre> # Define scaffold split splitter = splito.ScaffoldSplit(smiles=data.smiles.tolist(), n_jobs=-1, test_size=0.2, random_state=111) In\u00a0[4]: Copied! <pre>train_idx, test_idx = next(splitter.split(X=data[\"smiles\"].values))\nassert train_idx.shape[0] &gt; test_idx.shape[0]\n</pre> train_idx, test_idx = next(splitter.split(X=data[\"smiles\"].values)) assert train_idx.shape[0] &gt; test_idx.shape[0] In\u00a0[5]: Copied! <pre>data.loc[train_idx, \"ScaffoldSplit\"] = \"train\"\ndata.loc[test_idx, \"ScaffoldSplit\"] = \"test\"\ndata[\"scaffold\"] = splitter.scaffolds\n</pre> data.loc[train_idx, \"ScaffoldSplit\"] = \"train\" data.loc[test_idx, \"ScaffoldSplit\"] = \"test\" data[\"scaffold\"] = splitter.scaffolds In\u00a0[7]: Copied! <pre>visualize_chemspace(data, split_names=[\"ScaffoldSplit\"])\n</pre> visualize_chemspace(data, split_names=[\"ScaffoldSplit\"]) Out[7]: <pre>&lt;Figure size 640x480 with 0 Axes&gt;</pre> <pre>&lt;Figure size 640x480 with 0 Axes&gt;</pre> In\u00a0[8]: Copied! <pre>visualize_chemspace(data, split_names=[\"ScaffoldSplit\"], mol_col=\"scaffold\")\n</pre> visualize_chemspace(data, split_names=[\"ScaffoldSplit\"], mol_col=\"scaffold\") Out[8]: <pre>&lt;Figure size 640x480 with 0 Axes&gt;</pre> <pre>&lt;Figure size 640x480 with 0 Axes&gt;</pre> <ul> <li>The End :-)</li> </ul>"},{"location":"tutorials/The_Basics.html#splitting-dataset-with-splito","title":"Splitting dataset with <code>splito</code>\u00b6","text":"<p>A model is constructed using the training set, and this model is then used to make predictions for the compounds in the test set. The degree of agreement between the predicted and actual activity values for the test dataset, often quantified by metrics like R-squared, serves as an assessment of the model's internal consistency and  an indicator of the model's ability to make predictions. The prediction estimate depends on the specific criteria used for selecting compounds in the test set when compared to the true prospective prediction scenario.</p> <p>In drug discovery projects, various data splitting strategies are employed to train and evaluate machine learning models. These strategies help ensure that the model's performance is robust and can generalize well to new, unseen data.</p> <p>Common splitting strategies are <code>random split</code>, <code>time series split</code>, <code>scaffold-based split</code>, <code>stratified split</code> etc.</p>"},{"location":"tutorials/The_Basics.html#load-dataset","title":"Load dataset\u00b6","text":""},{"location":"tutorials/The_Basics.html#distribution-of-the-compounds-in-the-chemical-space","title":"Distribution of the compounds in the chemical space\u00b6","text":""},{"location":"tutorials/The_Basics.html#distribution-of-scaffolds-in-chemical-space","title":"Distribution of scaffolds in chemical space\u00b6","text":""},{"location":"tutorials/utils.html","title":"Utils","text":"In\u00a0[\u00a0]: Copied! <pre>from typing import List\n</pre> from typing import List In\u00a0[\u00a0]: Copied! <pre>from matplotlib import pyplot as plt\n</pre> from matplotlib import pyplot as plt In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport umap\nimport seaborn as sns\nimport datamol as dm\nimport warnings\n</pre> import pandas as pd import umap import seaborn as sns import datamol as dm import warnings In\u00a0[\u00a0]: Copied! <pre>warnings.filterwarnings(\"ignore\")\n</pre> warnings.filterwarnings(\"ignore\") In\u00a0[\u00a0]: Copied! <pre>def visualize_chemspace(data: pd.DataFrame, split_names: List[str], mol_col: str = \"smiles\", size_col=None):\n    figs = plt.figure(num=3)\n    features = [dm.to_fp(mol) for mol in data[mol_col]]\n    embedding = umap.UMAP().fit_transform(features)\n    data[\"UMAP_0\"], data[\"UMAP_1\"] = embedding[:, 0], embedding[:, 1]\n    for split_name in split_names:\n        plt.figure()\n        fig = sns.scatterplot(data=data, x=\"UMAP_0\", y=\"UMAP_1\", style=size_col, hue=split_name, alpha=0.7)\n        fig.set_title(f\"UMAP Embedding of compounds for {split_name}\")\n    return figs\n</pre> def visualize_chemspace(data: pd.DataFrame, split_names: List[str], mol_col: str = \"smiles\", size_col=None):     figs = plt.figure(num=3)     features = [dm.to_fp(mol) for mol in data[mol_col]]     embedding = umap.UMAP().fit_transform(features)     data[\"UMAP_0\"], data[\"UMAP_1\"] = embedding[:, 0], embedding[:, 1]     for split_name in split_names:         plt.figure()         fig = sns.scatterplot(data=data, x=\"UMAP_0\", y=\"UMAP_1\", style=size_col, hue=split_name, alpha=0.7)         fig.set_title(f\"UMAP Embedding of compounds for {split_name}\")     return figs"}]}